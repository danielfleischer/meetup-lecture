{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "The data is in a csv file. The first 8 columns are the features and the final binary column is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset[:, 0:8], dataset[:, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data to train and test, even though there is no testing step in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "We define a function to parse the hyper-parameters so each train is in a different folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model(batch,units,act,opt,drop):\n",
    "    p = lambda t: \",\".join(map(str,t))\n",
    "    return f\"batch={batch}_hidden={p(units)}_activation={act}_optimizer={opt}_dropout={drop:.0%}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A functiont o create a mobdel that takes different hyper-parameters we want to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(batch=10, units=(5,3,3), act='relu', opt='adam', drop=0.5, i=0):\n",
    "    input_0 = Input(shape=(8,))\n",
    "    input_1 = Dropout(drop)(input_0)\n",
    "    \n",
    "    layer_0 = Dropout(drop)(Dense(units[0], input_dim=8, activation=act)(input_1))\n",
    "    \n",
    "    if len(units) > 1:\n",
    "        for i,l in enumerate(units,1):\n",
    "            exec(f\"layer_{i} = Dropout({drop})(Dense({l}, activation='{act}')(layer_{i-1}))\")\n",
    "\n",
    "    final = eval(f\"Dense(1, activation='sigmoid')(layer_{i})\")\n",
    "    \n",
    "    model = Model(inputs=[input_0], outputs=[final])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    stopping = keras.callbacks.EarlyStopping(patience=5)\n",
    "    tensor = keras.callbacks.TensorBoard(log_dir='./Graph/' + parse_model(batch,units,act,opt,drop))\n",
    "    \n",
    "    return model,[tensor,stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a model given parameters and trains it for 100 epochs or less if the early stopping kicks in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(args):\n",
    "    K.clear_session()\n",
    "    print(\"Training model:\" + parse_model(**args))\n",
    "    model, calls = create_model(**args)\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=args['batch'], validation_split=0.2, verbose=0, callbacks=calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the SKlearn `ParameterGrid` to generate a list of dictionaries with all the different combinations to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ParameterGrid({'batch': [10,40], \n",
    "                        'units':[(4,), (8,4)],\n",
    "                        'act': ['relu', 'tanh'], \n",
    "                        'opt': ['adam','adadelta'],\n",
    "                        'drop': [0.5, 0.9]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we make sure there is a folder called `Graph` otherwise we'll get an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "The main loop; for each paramter configuration, we train a model. Each model will have a different folder inside `./Graph/` so tensorboard knows to treat them as different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params:\n",
    "    train_model(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
